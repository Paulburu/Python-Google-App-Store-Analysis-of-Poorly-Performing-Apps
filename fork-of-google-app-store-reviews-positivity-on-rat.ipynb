{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Summary**: the purpose of this project is to check whether reviews in the AppStore have any correlation (or predictive influence) with the App's overall score (1 to 5 stars). \n# \n# **Motivation**: if a significant relationship can be established, App creators will know that reviews are an important source of data and that, perhaps, more focus should be put into interacting with users and analyzing feedback, therefore more efficiently utilizing time and money based resources\n# \n# **Method**: the datasets used come from fellow Kaggle user Lavanya Gupta under the title \"Google Play Store Apps - Web scraped data of 10k Play Store apps for analysing the Android market.\"","metadata":{}},{"cell_type":"code","source":"import pandas as pd\n\n#reading the 2 datasets\n\ndata1 = pd.read_csv('../input/googleplaystore-data/googleplaystore.csv')\ndata2 = pd.read_csv('../input/googleplaystore-data/googleplaystore_user_reviews.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:31:49.698071Z","iopub.execute_input":"2021-07-11T20:31:49.698454Z","iopub.status.idle":"2021-07-11T20:31:49.8796Z","shell.execute_reply.started":"2021-07-11T20:31:49.698422Z","shell.execute_reply":"2021-07-11T20:31:49.878585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset 1\n\ndata1.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:31:49.880908Z","iopub.execute_input":"2021-07-11T20:31:49.881188Z","iopub.status.idle":"2021-07-11T20:31:49.900058Z","shell.execute_reply.started":"2021-07-11T20:31:49.88116Z","shell.execute_reply":"2021-07-11T20:31:49.898939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dataset 2\n#It can be noticed that dataset 2 presents 3 columns : Sentiment, Sentiment_Polarity, Sentiment_Subjectivity which show the magnitude\n# of a review and give it a positiveness score. I'm planning to do my own analysis using the textblob library to verify the results\n\ndata2.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:31:49.901788Z","iopub.execute_input":"2021-07-11T20:31:49.902118Z","iopub.status.idle":"2021-07-11T20:31:49.921208Z","shell.execute_reply.started":"2021-07-11T20:31:49.902067Z","shell.execute_reply":"2021-07-11T20:31:49.91988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#using textblob\n#After running the code block you'll notice that we get the exact same polarity and subjectivity as the original daataset creator which\n# could suggest that we used similar methods. Safe to say, the sentiment analysis looks good.\nfrom textblob import TextBlob\n\ndata = data2\ndata = data.dropna()\n\ndef getSubjectivity(text):\n    return TextBlob(text).sentiment.subjectivity\n\ndef getPolarity(text):\n    return TextBlob(text).sentiment.polarity\n\ndata['Polarity'] = data['Translated_Review'].apply(getPolarity)\ndata['Subjectivity'] = data['Translated_Review'].apply(getSubjectivity)\n\nprint(data.head(5))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:31:49.922926Z","iopub.execute_input":"2021-07-11T20:31:49.923257Z","iopub.status.idle":"2021-07-11T20:32:09.099813Z","shell.execute_reply.started":"2021-07-11T20:31:49.923227Z","shell.execute_reply":"2021-07-11T20:32:09.098897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Eventually, we will have to combine the datasets, so now would be a good time to check if they're compatible for a merge\n\n#Dataset #2 has many more rows, but this is to be expected. Data set #1 at first glance contains a list of unique app names\n# and their attributes, and dataset #2 contains multiple reviews per same-app name so this will result in more occurances.\n\nprint(data1.shape)\nprint(data2.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.101026Z","iopub.execute_input":"2021-07-11T20:32:09.101558Z","iopub.status.idle":"2021-07-11T20:32:09.106471Z","shell.execute_reply.started":"2021-07-11T20:32:09.101515Z","shell.execute_reply":"2021-07-11T20:32:09.105656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# At this point, I had to make a decision.\nIn order to combine the datasets into one, model-ready dataset, I had to find a way to make them compatible. I concluded that I'm going to \"compress\" dataset #2 by taking the average of the sentiment score per unique app-name and thus obtaining values that could be added to dataset #1","metadata":{}},{"cell_type":"code","source":"#drop missing values in both datasets\ndata1 = data1.dropna()\ndata2 = data2.dropna()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.107688Z","iopub.execute_input":"2021-07-11T20:32:09.108186Z","iopub.status.idle":"2021-07-11T20:32:09.149527Z","shell.execute_reply.started":"2021-07-11T20:32:09.108146Z","shell.execute_reply":"2021-07-11T20:32:09.148453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create new dataset with average sentiment polarity per unique app name\n\n#it apears that out of the ~11,000 data points we found in dataset1, we only have reviews for 865 of them. This greatly reduces our dataset.\n\ntemp_data = data2.groupby('App')['Sentiment_Polarity'].mean().to_frame('Sentiment').reset_index()\nprint(temp_data)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.151138Z","iopub.execute_input":"2021-07-11T20:32:09.151592Z","iopub.status.idle":"2021-07-11T20:32:09.173211Z","shell.execute_reply.started":"2021-07-11T20:32:09.151541Z","shell.execute_reply":"2021-07-11T20:32:09.172012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#merge data set 1 aand new data set on app name\ndata = temp_data.merge(data1,  on='App', how='left')\ndata = data.dropna()\ndata.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.17616Z","iopub.execute_input":"2021-07-11T20:32:09.176562Z","iopub.status.idle":"2021-07-11T20:32:09.216373Z","shell.execute_reply.started":"2021-07-11T20:32:09.17652Z","shell.execute_reply":"2021-07-11T20:32:09.215336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#remove duplicates\ndata = data.drop_duplicates()\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.217931Z","iopub.execute_input":"2021-07-11T20:32:09.218245Z","iopub.status.idle":"2021-07-11T20:32:09.245466Z","shell.execute_reply.started":"2021-07-11T20:32:09.218203Z","shell.execute_reply":"2021-07-11T20:32:09.244261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#new shape\n#Notice that the new number of rows 1078 is bigger than 865 a few blocks ago even after removing missing value rows and duplicates.\n# This may be because some apps, even though they have the same naame, might be present in different categories.\n\ndata.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.247017Z","iopub.execute_input":"2021-07-11T20:32:09.247427Z","iopub.status.idle":"2021-07-11T20:32:09.252906Z","shell.execute_reply.started":"2021-07-11T20:32:09.247384Z","shell.execute_reply":"2021-07-11T20:32:09.25196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop unneeded features\ndata = data.drop(['Genres','Last Updated','Current Ver','Android Ver'],axis=1)\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.25421Z","iopub.execute_input":"2021-07-11T20:32:09.254731Z","iopub.status.idle":"2021-07-11T20:32:09.27747Z","shell.execute_reply.started":"2021-07-11T20:32:09.254692Z","shell.execute_reply":"2021-07-11T20:32:09.276455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#simplify 33 categories into 7 (based on personal opinion)\n# eg: game, sports, and comics will be 'Entertainment'\n\ndata = data.replace({'Category' : {'SHOPPING' : 'LIFESTYLE', 'HEALTH_AND_FITNESS':'EDUCATIONAL',\n                                  'GAME':'ENTERTAINMENT','SPORTS':'ENTERTAINMENT','COMICS':'ENTERTAINMENT',\n                                  'FOOD_AND_DRINK':'ENTERTAINMENT','HEALTH_AND_FITNESS':'EDUCATIONAL',\n                                  'MEDICAL':'EDUCATIONAL','FINANCE':'EDUCATIONAL','EDUCATION':'EDUCATIONAL',\n                                  'BUSINESS':'EDUCATIONAL','NEWS_AND_MAGAZINES':'INFORMATIONAL',\n                                  'WEATHER':'INFORMATIONAL','MAPS_AND_NAVIGATION':'INFORMATIONAL',\n                                  'HOUSE_AND_HOME':'INFORMATIONAL','PARENTING':'INFORMATIONAL',\n                                  'COMMUNICATION':'SOCIAL','DATING':'SOCIAL','FAMILY':'SOCIAL',\n                                  'EVENTS':'SOCIAL','TRAVEL_AND_LOCAL':'SOCIAL','BEAUTY':'ARTnBEAUTY',\n                                  'PHOTOGRAPHY':'ARTnBEAUTY','ART_AND_DESIGN':'ARTnBEAUTY',\n                                  'PRODUCTIVITY':'LIFESTYLE','PERSONALIZATION':'LIFESTYLE',\n                                  'BOOKS_AND_REFERENCE':'TOOLS','VIDEO_PLAYERS':'ENTERTAINMENT',\n                                  'AUTO_AND_VEHICLES':'TOOLS','LIBRARIES_AND_DEMO':'TOOLS'}})\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.279045Z","iopub.execute_input":"2021-07-11T20:32:09.279472Z","iopub.status.idle":"2021-07-11T20:32:09.312636Z","shell.execute_reply.started":"2021-07-11T20:32:09.279431Z","shell.execute_reply":"2021-07-11T20:32:09.311564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transform number of reviews in int\n\ndata['Reviews']  = data['Reviews'].apply(lambda x: int(x))\ndata.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:09.314143Z","iopub.execute_input":"2021-07-11T20:32:09.314568Z","iopub.status.idle":"2021-07-11T20:32:09.333854Z","shell.execute_reply.started":"2021-07-11T20:32:09.314525Z","shell.execute_reply":"2021-07-11T20:32:09.332699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transform size of app in float \n\ndrrp = data\ndrrp['Size'] = drrp['Size'].apply(lambda x: str(x).replace('Varies with device', 'NaN') if 'Varies with device' in str(x) else x)\ndrrp['Size'] = drrp['Size'].apply(lambda x: str(x).replace('M', '') if 'M' in str(x) else x)\ndrrp['Size'] = drrp['Size'].apply(lambda x: str(x).replace(',', '') if 'M' in str(x) else x)\ndrrp['Size'] = drrp['Size'].apply(lambda x: float(str(x).replace('k', '')) / 1000 if 'k' in str(x) else x)\ndrrp['Size'] = drrp['Size'].apply(lambda x: float(x))\n\ndrrp = drrp.dropna()\ndrrp.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:48.170815Z","iopub.execute_input":"2021-07-11T20:32:48.171183Z","iopub.status.idle":"2021-07-11T20:32:48.201658Z","shell.execute_reply.started":"2021-07-11T20:32:48.171145Z","shell.execute_reply":"2021-07-11T20:32:48.200551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#transform number of installs in int\n\ndf = drrp\ndf['Installs'] = df['Installs'].apply(lambda x: x.replace('+', '') if '+' in str(x) else x)\ndf['Installs'] = df['Installs'].apply(lambda x: x.replace(',', '') if ',' in str(x) else x)\ndf['Installs'] = df['Installs'].apply(lambda x: int(x))\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:32:58.511593Z","iopub.execute_input":"2021-07-11T20:32:58.511935Z","iopub.status.idle":"2021-07-11T20:32:58.53407Z","shell.execute_reply.started":"2021-07-11T20:32:58.511906Z","shell.execute_reply":"2021-07-11T20:32:58.532958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#with type and price is more complicated so let's check if there's aany point to consider them\n# only 1.5% of values are paid so it might not be a baad idea to remove those attributes for simplicity\ndf['Type'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:33:04.248585Z","iopub.execute_input":"2021-07-11T20:33:04.249135Z","iopub.status.idle":"2021-07-11T20:33:04.256638Z","shell.execute_reply.started":"2021-07-11T20:33:04.249072Z","shell.execute_reply":"2021-07-11T20:33:04.255688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#drop type and price due to the fact that we have too few paid values\ndf = df.drop(['Type','Price'],axis=1)\n\n#drop app name as it is no longer important\ndf =  df.drop(labels=['App'],axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:33:06.881223Z","iopub.execute_input":"2021-07-11T20:33:06.881575Z","iopub.status.idle":"2021-07-11T20:33:06.888409Z","shell.execute_reply.started":"2021-07-11T20:33:06.881545Z","shell.execute_reply":"2021-07-11T20:33:06.887438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#clean dataset\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:33:13.832553Z","iopub.execute_input":"2021-07-11T20:33:13.833157Z","iopub.status.idle":"2021-07-11T20:33:13.849505Z","shell.execute_reply.started":"2021-07-11T20:33:13.83312Z","shell.execute_reply":"2021-07-11T20:33:13.848268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Correlation matrix on numerical data\n# not very promising results. There doesn't seem to be any attribute that greatly correlates with Raating. However, the sentiment does have the better score\n# which is good. No great correlation between the other attributes either, other than size and reviews with a .42 being the highest\ndata = df\ndata[['Rating','Sentiment','Reviews','Size','Installs']].corr()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:33:20.637129Z","iopub.execute_input":"2021-07-11T20:33:20.637611Z","iopub.status.idle":"2021-07-11T20:33:20.650839Z","shell.execute_reply.started":"2021-07-11T20:33:20.637581Z","shell.execute_reply":"2021-07-11T20:33:20.650084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Create dummies for category variable and content rating variable\ndummydata = data\ndummycategory = pd.get_dummies(dummydata.Category)\ndummycontentage =  pd.get_dummies(dummydata['Content Rating'])\n\n#Replace initial category and content rating columns with the newly created dummy columns\n\ndummydata = dummydata.drop(labels=['Category','Content Rating'],axis=1)\n\nframes = [dummydata,  dummycategory, dummycontentage]\ndummydatas = pd.concat(frames,  axis=1)\n\ndummydatas.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:37:29.498613Z","iopub.execute_input":"2021-07-11T20:37:29.498961Z","iopub.status.idle":"2021-07-11T20:37:29.522841Z","shell.execute_reply.started":"2021-07-11T20:37:29.498926Z","shell.execute_reply":"2021-07-11T20:37:29.521927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt; plt.rcdefaults()\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport  math\nfrom random import randint\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport matplotlib\nmatplotlib.axes.Axes.pie\nmatplotlib.pyplot.pie","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:45:07.118259Z","iopub.execute_input":"2021-07-11T20:45:07.118637Z","iopub.status.idle":"2021-07-11T20:45:07.128073Z","shell.execute_reply.started":"2021-07-11T20:45:07.118598Z","shell.execute_reply":"2021-07-11T20:45:07.127063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Regression model 1 tests all the attributes without sentiment on rating\n\ndata2 = dummydatas\n\n#initialize dependent and independent variables\nY = data2['Rating']\nX_nsent = data2.drop(labels=['Rating','Sentiment'],axis=1)\n\n#divide data training 80% and test 20%\nX_nsent_train, X_nsent_test, Y_train, Y_test = train_test_split(X_nsent,Y,test_size=0.2)\n\n#create model\nmodel = linear_model.LinearRegression()\n\nmodel.fit(X_nsent_train, Y_train)\n\nY_pred = model.predict(X_nsent_test)\n\nprint('Coefficients ',model.coef_)\nprint('Intercept ',model.intercept_)\nprint('Mean squared error (MSE): %.2f'  %  mean_squared_error(Y_test,Y_pred))\nprint('Coefficient of determination (R^2): %.2f' % r2_score(Y_test,Y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:45:09.637552Z","iopub.execute_input":"2021-07-11T20:45:09.638056Z","iopub.status.idle":"2021-07-11T20:45:09.86816Z","shell.execute_reply.started":"2021-07-11T20:45:09.638004Z","shell.execute_reply":"2021-07-11T20:45:09.867457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Regression model 2 tests all the attributes \ndata2 = dummydatas\n\nY = pd.DataFrame(data2['Rating'])\nX_sent = data2.drop(labels=['Rating'],axis=1)\n\nX_sent_train, X_sent_test, Y_train, Y_test = train_test_split(X_sent,Y,test_size=0.2)\n\nmodel = linear_model.LinearRegression()\n\nmodel.fit(X_sent_train, Y_train)\n\nY_pred = model.predict(X_sent_test)\n\nprint('Coefficients ',model.coef_)\nprint('Intercept ',model.intercept_)\nprint('Mean squared error (MSE): %.2f'  %  mean_squared_error(Y_test,Y_pred))\nprint('Coefficient of determination (R^2): %.2f' % r2_score(Y_test,Y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:45:32.315112Z","iopub.execute_input":"2021-07-11T20:45:32.315481Z","iopub.status.idle":"2021-07-11T20:45:32.337449Z","shell.execute_reply.started":"2021-07-11T20:45:32.315445Z","shell.execute_reply":"2021-07-11T20:45:32.336406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Regression model 3 tests sentiment on rating\ndata2 = dummydatas\n\nY = pd.DataFrame(data2['Rating'])\nX = pd.DataFrame(data2['Sentiment'])\n\nX_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2)\n\nmodel = linear_model.LinearRegression()\n\nmodel.fit(X_train, Y_train)\n\nY_pred = model.predict(X_test)\n\nprint('Coefficients ',model.coef_)\nprint('Intercept ',model.intercept_)\nprint('Mean squared error (MSE): %.2f'  %  mean_squared_error(Y_test,Y_pred))\nprint('Coefficient of determination (R^2): %.2f' % r2_score(Y_test,Y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T20:45:57.075337Z","iopub.execute_input":"2021-07-11T20:45:57.075725Z","iopub.status.idle":"2021-07-11T20:45:57.103505Z","shell.execute_reply.started":"2021-07-11T20:45:57.075687Z","shell.execute_reply":"2021-07-11T20:45:57.102385Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Best model seems to include all attributes, including sentiment, as denoted by the coefficient of determination.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}